"""add_agent_registry_tables

Revision ID: 5fa6f1679964
Revises: f8913c227d18
Create Date: 2025-10-17 01:25:57.725263

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = "5fa6f1679964"
down_revision = "f8913c227d18"
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "agent_specs",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("name", sa.String(length=255), nullable=False),
        sa.Column("version", sa.String(length=50), nullable=False),
        sa.Column("agent_type", sa.String(length=100), nullable=False),
        sa.Column("spec_yaml", sa.Text(), nullable=False),
        sa.Column("spec_compiled", sa.JSON(), nullable=False),
        sa.Column("description", sa.Text(), nullable=True),
        sa.Column("created_by", sa.String(length=255), nullable=True),
        sa.Column("created_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("updated_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("is_active", sa.Boolean(), nullable=False),
        sa.Column("is_latest", sa.Boolean(), nullable=False),
        sa.Column("deprecated_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("deprecation_reason", sa.Text(), nullable=True),
        sa.Column("tags", postgresql.ARRAY(sa.String()), nullable=True),
        sa.Column("category", sa.String(length=100), nullable=True),
        sa.Column("validation_status", sa.String(length=50), nullable=True),
        sa.Column("validation_errors", sa.JSON(), nullable=True),
        sa.Column("validation_warnings", sa.JSON(), nullable=True),
        sa.Column("usage_count", sa.Integer(), nullable=False),
        sa.Column("last_used_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("total_execution_time_ms", sa.Integer(), nullable=False),
        sa.Column("total_cost", sa.Float(), nullable=False),
        sa.Column("success_count", sa.Integer(), nullable=False),
        sa.Column("failure_count", sa.Integer(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index("idx_agent_spec_active", "agent_specs", ["is_active"], unique=False)
    op.create_index(
        "idx_agent_spec_active_latest",
        "agent_specs",
        ["is_active", "is_latest"],
        unique=False,
    )
    op.create_index(
        "idx_agent_spec_category", "agent_specs", ["category"], unique=False
    )
    op.create_index(
        "idx_agent_spec_created", "agent_specs", ["created_at"], unique=False
    )
    op.create_index("idx_agent_spec_latest", "agent_specs", ["is_latest"], unique=False)
    op.create_index("idx_agent_spec_name", "agent_specs", ["name"], unique=False)
    op.create_index(
        "idx_agent_spec_name_version", "agent_specs", ["name", "version"], unique=True
    )
    op.create_index(op.f("ix_agent_specs_name"), "agent_specs", ["name"], unique=False)
    op.create_table(
        "agent_executions",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("agent_spec_id", sa.UUID(), nullable=False),
        sa.Column("workflow_id", sa.UUID(), nullable=True),
        sa.Column("workflow_node_id", sa.String(length=255), nullable=True),
        sa.Column("agent_id", sa.String(length=255), nullable=False),
        sa.Column("execution_context", sa.JSON(), nullable=True),
        sa.Column("started_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("completed_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("execution_time_ms", sa.Integer(), nullable=True),
        sa.Column("status", sa.String(length=50), nullable=False),
        sa.Column("result_data", sa.JSON(), nullable=True),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.Column("error_traceback", sa.Text(), nullable=True),
        sa.Column("token_count", sa.Integer(), nullable=True),
        sa.Column("cost", sa.Float(), nullable=True),
        sa.Column("memory_mb_peak", sa.Integer(), nullable=True),
        sa.Column("success_metrics", sa.JSON(), nullable=True),
        sa.Column("all_metrics_passed", sa.Boolean(), nullable=True),
        sa.ForeignKeyConstraint(
            ["agent_spec_id"], ["agent_specs.id"], ondelete="CASCADE"
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "idx_agent_exec_completed", "agent_executions", ["completed_at"], unique=False
    )
    op.create_index(
        "idx_agent_exec_spec_id", "agent_executions", ["agent_spec_id"], unique=False
    )
    op.create_index(
        "idx_agent_exec_spec_status",
        "agent_executions",
        ["agent_spec_id", "status"],
        unique=False,
    )
    op.create_index(
        "idx_agent_exec_started", "agent_executions", ["started_at"], unique=False
    )
    op.create_index(
        "idx_agent_exec_status", "agent_executions", ["status"], unique=False
    )
    op.create_index(
        "idx_agent_exec_workflow", "agent_executions", ["workflow_id"], unique=False
    )
    # Drop audit_logs table and indexes if they exist (safe for fresh databases)
    # Use raw SQL with IF EXISTS to handle cases where table/index doesn't exist
    op.execute("DROP INDEX IF EXISTS idx_agent_timestamp")
    op.execute("DROP INDEX IF EXISTS idx_event_severity")
    op.execute("DROP INDEX IF EXISTS idx_workflow_timestamp")
    op.execute("DROP TABLE IF EXISTS audit_logs")
    op.drop_constraint(
        "conversation_metrics_conversation_id_fkey",
        "conversation_metrics",
        type_="foreignkey",
    )
    op.create_foreign_key(
        None, "conversation_metrics", "conversations", ["conversation_id"], ["id"]
    )
    op.drop_index("idx_conversation_status", table_name="conversations")
    op.drop_index(
        "idx_conversation_tags", table_name="conversations", postgresql_using="gin"
    )
    op.drop_index("idx_conversation_time_range", table_name="conversations")
    op.drop_index("idx_conversation_workflow", table_name="conversations")
    op.create_index("idx_status", "conversations", ["status"], unique=False)
    op.create_index(
        "idx_tags", "conversations", ["tags"], unique=False, postgresql_using="gin"
    )
    op.create_index(
        "idx_time_range", "conversations", ["start_time", "end_time"], unique=False
    )
    op.create_index("idx_workflow", "conversations", ["workflow_id"], unique=False)
    op.create_index(
        op.f("ix_conversations_workflow_id"),
        "conversations",
        ["workflow_id"],
        unique=False,
    )
    op.drop_constraint(
        "conversations_parent_conversation_id_fkey", "conversations", type_="foreignkey"
    )
    op.create_foreign_key(
        None, "conversations", "conversations", ["parent_conversation_id"], ["id"]
    )
    op.alter_column(
        "external_publishers", "is_active", existing_type=sa.BOOLEAN(), nullable=True
    )
    op.alter_column(
        "external_publishers",
        "created_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=True,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "external_publishers",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=True,
        existing_server_default=sa.text("now()"),
    )
    op.drop_index("idx_message_agent_timestamp", table_name="messages")
    op.drop_index("idx_message_conversation_timestamp", table_name="messages")
    op.drop_index("idx_message_message_type", table_name="messages")
    op.drop_index("idx_message_timestamp", table_name="messages")
    op.create_index(
        "idx_agent_timestamp", "messages", ["agent_id", "timestamp"], unique=False
    )
    op.create_index(
        "idx_conversation_timestamp",
        "messages",
        ["conversation_id", "timestamp"],
        unique=False,
    )
    op.create_index("idx_message_type", "messages", ["message_type"], unique=False)
    op.create_index("idx_timestamp", "messages", ["timestamp"], unique=False)
    op.drop_constraint("messages_conversation_id_fkey", "messages", type_="foreignkey")
    op.drop_constraint(
        "messages_parent_message_id_fkey", "messages", type_="foreignkey"
    )
    op.create_foreign_key(
        None, "messages", "conversations", ["conversation_id"], ["id"]
    )
    op.create_foreign_key(None, "messages", "messages", ["parent_message_id"], ["id"])
    op.alter_column(
        "workflow_agents",
        "registered_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=True,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "workflow_events",
        "created_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=True,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "workflow_specs",
        "created_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=True,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "workflow_specs",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=True,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "workflows",
        "created_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=True,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "workflows",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=True,
        existing_server_default=sa.text("now()"),
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column(
        "workflows",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "workflows",
        "created_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "workflow_specs",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "workflow_specs",
        "created_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "workflow_events",
        "created_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "workflow_agents",
        "registered_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.drop_constraint(None, "messages", type_="foreignkey")
    op.drop_constraint(None, "messages", type_="foreignkey")
    op.create_foreign_key(
        "messages_parent_message_id_fkey",
        "messages",
        "messages",
        ["parent_message_id"],
        ["id"],
        ondelete="SET NULL",
    )
    op.create_foreign_key(
        "messages_conversation_id_fkey",
        "messages",
        "conversations",
        ["conversation_id"],
        ["id"],
        ondelete="CASCADE",
    )
    op.drop_index("idx_timestamp", table_name="messages")
    op.drop_index("idx_message_type", table_name="messages")
    op.drop_index("idx_conversation_timestamp", table_name="messages")
    op.drop_index("idx_agent_timestamp", table_name="messages")
    op.create_index("idx_message_timestamp", "messages", ["timestamp"], unique=False)
    op.create_index(
        "idx_message_message_type", "messages", ["message_type"], unique=False
    )
    op.create_index(
        "idx_message_conversation_timestamp",
        "messages",
        ["conversation_id", "timestamp"],
        unique=False,
    )
    op.create_index(
        "idx_message_agent_timestamp",
        "messages",
        ["agent_id", "timestamp"],
        unique=False,
    )
    op.alter_column(
        "external_publishers",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "external_publishers",
        "created_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "external_publishers", "is_active", existing_type=sa.BOOLEAN(), nullable=False
    )
    op.drop_constraint(None, "conversations", type_="foreignkey")
    op.create_foreign_key(
        "conversations_parent_conversation_id_fkey",
        "conversations",
        "conversations",
        ["parent_conversation_id"],
        ["id"],
        ondelete="CASCADE",
    )
    op.drop_index(op.f("ix_conversations_workflow_id"), table_name="conversations")
    op.drop_index("idx_workflow", table_name="conversations")
    op.drop_index("idx_time_range", table_name="conversations")
    op.drop_index("idx_tags", table_name="conversations", postgresql_using="gin")
    op.drop_index("idx_status", table_name="conversations")
    op.create_index(
        "idx_conversation_workflow", "conversations", ["workflow_id"], unique=False
    )
    op.create_index(
        "idx_conversation_time_range",
        "conversations",
        ["start_time", "end_time"],
        unique=False,
    )
    op.create_index(
        "idx_conversation_tags",
        "conversations",
        ["tags"],
        unique=False,
        postgresql_using="gin",
    )
    op.create_index(
        "idx_conversation_status", "conversations", ["status"], unique=False
    )
    op.drop_constraint(None, "conversation_metrics", type_="foreignkey")
    op.create_foreign_key(
        "conversation_metrics_conversation_id_fkey",
        "conversation_metrics",
        "conversations",
        ["conversation_id"],
        ["id"],
        ondelete="CASCADE",
    )
    op.create_table(
        "audit_logs",
        sa.Column("id", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column(
            "timestamp", postgresql.TIMESTAMP(), autoincrement=False, nullable=False
        ),
        sa.Column("event_type", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("severity", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("workflow_id", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("agent_id", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("agent_type", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("agent_name", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("action", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("description", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column(
            "details",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("duration_ms", sa.BIGINT(), autoincrement=False, nullable=True),
        sa.Column("error_type", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("error_message", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column("error_traceback", sa.TEXT(), autoincrement=False, nullable=True),
        sa.PrimaryKeyConstraint("id", name="audit_logs_pkey"),
    )
    op.create_index(
        "idx_workflow_timestamp",
        "audit_logs",
        ["workflow_id", "timestamp"],
        unique=False,
    )
    op.create_index(
        "idx_event_severity", "audit_logs", ["event_type", "severity"], unique=False
    )
    op.create_index(
        "idx_agent_timestamp", "audit_logs", ["agent_id", "timestamp"], unique=False
    )
    op.drop_index("idx_agent_exec_workflow", table_name="agent_executions")
    op.drop_index("idx_agent_exec_status", table_name="agent_executions")
    op.drop_index("idx_agent_exec_started", table_name="agent_executions")
    op.drop_index("idx_agent_exec_spec_status", table_name="agent_executions")
    op.drop_index("idx_agent_exec_spec_id", table_name="agent_executions")
    op.drop_index("idx_agent_exec_completed", table_name="agent_executions")
    op.drop_table("agent_executions")
    op.drop_index(op.f("ix_agent_specs_name"), table_name="agent_specs")
    op.drop_index("idx_agent_spec_name_version", table_name="agent_specs")
    op.drop_index("idx_agent_spec_name", table_name="agent_specs")
    op.drop_index("idx_agent_spec_latest", table_name="agent_specs")
    op.drop_index("idx_agent_spec_created", table_name="agent_specs")
    op.drop_index("idx_agent_spec_category", table_name="agent_specs")
    op.drop_index("idx_agent_spec_active_latest", table_name="agent_specs")
    op.drop_index("idx_agent_spec_active", table_name="agent_specs")
    op.drop_table("agent_specs")
    # ### end Alembic commands ###
